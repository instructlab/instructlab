# SPDX-License-Identifier: Apache-2.0

click>=8.1.7,<9.0.0
click-didyoumean>=0.3.0
datasets>=2.18.0
gguf>=0.6.0
GitPython>=3.1.42
httpx>=0.25.0
instructlab-eval>=0.4.2
instructlab-quantize>=0.1.0
instructlab-schema>=0.4.0
instructlab-sdg>=0.6.2
instructlab-training>=0.6.0
llama_cpp_python[server]==0.3.2
mlx>=0.5.1,<0.6.0; sys_platform == 'darwin' and platform_machine == 'arm64'
numpy>=1.26.4,<2.0.0
openai>=1.13.3
peft>=0.9.0
prompt-toolkit>=3.0.38
pydantic>=2.7.4
pydantic_yaml>=1.2.0
PyYAML>=6.0.0
rich>=13.3.1
rouge-score>=0.1.2
ruamel.yaml>=0.17.0
sentencepiece>=0.2.0
# "old" version required for vLLM on CUDA to build
tokenizers>=0.11.1
toml>=0.10.2
# Default version. Can be overridden in extra requirements
torch>=2.3.0,<2.5.0
tqdm>=4.66.2
# 'optimum' for Intel Gaudi needs transformers <4.44.0,>=4.43.0
transformers>=4.41.2
trl>=0.12.2
wandb>=0.16.4
xdg-base-dirs>=6.0.1
psutil>=6.0.0
huggingface_hub[hf_transfer]>=0.1.8
