# `ilab` Command Reference

```text
Usage: ilab [OPTIONS] COMMAND [ARGS]...

  CLI for interacting with InstructLab.

  If this is your first time running ilab, it's best to start with `ilab init`
  to create the environment.

Options:
  --config PATH  Path to a configuration file.  [default: config.yaml]
  --version      Show the version and exit.
  --help         Show this message and exit.

Commands:
  config    Command Group for Interacting with the Config of InstructLab.
  data      Command Group for Interacting with the Data generated by...
  model     Command Group for Interacting with the Models in InstructLab.
  sysinfo   Print system information
  taxonomy  Command Group for Interacting with the Taxonomy of InstructLab.

Aliases:
  chat: model chat
  convert: model convert
  diff: taxonomy diff
  download: model download
  generate: data generate
  init: config init
  serve: model serve
  test: model test
  train: model train
```

* [`ilab config` Commands](#ilab-config-commands)
  * [`ilab config init` Command](#ilab-config-init-command)
* [`ilab data` Commands](#ilab-data-commands)
  * [`ilab data generate` Command](#ilab-data-generate-command)
* [`ilab model` Commands](#ilab-model-commands)
  * [`ilab model chat` Command](#ilab-model-chat-command)
  * [`ilab model convert` Command](#ilab-model-convert-command)
  * [`ilab model download` Command](#ilab-model-download-command)
  * [`ilab model serve` Command](#ilab-model-serve-command)
  * [`ilab model test` Command](#ilab-model-test-command)
  * [`ilab model train` Command](#ilab-model-train-command)
* [`ilab sysinfo` Commands](#ilab-sysinfo-commands)
* [`ilab taxonomy` Commands](#ilab-taxonomy-commands)
  * [`ilab taxonomy diff` Command](#ilab-taxonomy-diff-command)

## `ilab config` Commands

```text
Usage: ilab config [OPTIONS] COMMAND [ARGS]...

  Command Group for Interacting with the Config of InstructLab.

  If this is your first time running ilab, it's best to start with `ilab init`
  to create the environment.

Options:
  --help  Show this message and exit.

Commands:
  init  Initializes environment for InstructLab
```

### `ilab config init` Command

```text
Usage: ilab config init [OPTIONS]

  Initializes environment for InstructLab

Options:
  --interactive / --non-interactive
                                  Initialize the environment assuming
                                  defaults.  [default: interactive]
  --model-path PATH               Path to the model used during generation.
                                  [default:
                                  models/merlinite-7b-lab-Q4_K_M.gguf]
  --taxonomy-base TEXT            Base git-ref to use when listing/generating
                                  new taxonomy.  [default: origin/main]
  --taxonomy-path PATH            Path to
                                  https://github.com/instructlab/taxonomy.git
                                  clone.  [default: taxonomy]
  --repository TEXT               Taxonomy repository location.  [default:
                                  https://github.com/instructlab/taxonomy.git]
  --min-taxonomy                  Shallow clone the taxonomy repository with
                                  minimum size. Please do not use this option
                                  if you are planning to contribute back using
                                  the same taxonomy repository.
  --help                          Show this message and exit.
```

## `ilab data` Commands

```text
Usage: ilab data [OPTIONS] COMMAND [ARGS]...

  Command Group for Interacting with the Data generated by InstructLab.

  If this is your first time running ilab, it's best to start with `ilab init`
  to create the environment.

Options:
  --help  Show this message and exit.

Commands:
  generate  Generates synthetic data to enhance your example data
```

### `ilab data generate` Command

```text
Usage: ilab data generate [OPTIONS]

  Generates synthetic data to enhance your example data

Options:
  --model TEXT                Name of the model used during generation.
                              [default: models/merlinite-7b-lab-Q4_K_M.gguf]
  --num-cpus INTEGER          Number of processes to use.  [default: 10]
  --chunk-word-count INTEGER  Number of words to chunk the document  [default:
                              1000]
  --num-instructions INTEGER  Number of instructions to generate.  [default:
                              100]
  --taxonomy-path PATH        Path to
                              https://github.com/instructlab/taxonomy.git
                              clone or local file path.  [default: taxonomy]
  --taxonomy-base TEXT        Base git-ref to use when generating new
                              taxonomy.  [default: origin/main]
  --output-dir PATH           Path to output generated files.
  --rouge-threshold FLOAT     Threshold of (max) Rouge score to keep samples;
                              1.0 means accept all samples.  [default: 0.9]
  --quiet                     Suppress output of synthesized instructions.
  --endpoint-url TEXT         Custom URL endpoint for OpenAI-compatible API.
                              Defaults to the `ilab model serve` endpoint.
  --api-key TEXT              API key for API endpoint. [default:
                              config.DEFAULT_API_KEY]
  --yaml-rules PATH           Custom rules file for YAML linting.
  --server-ctx-size INTEGER   The context size is the maximum number of tokens
                              the server will consider.  [default: 4096]
  --tls-insecure              Disable TLS verification.
  --tls-client-cert PATH      Path to the TLS client certificate to use.
  --tls-client-key PATH       Path to the TLS client key to use.
  --tls-client-passwd TEXT    TLS client certificate password.
  --model-family TEXT         Force model family to use when picking a
                              generation template
  --help                      Show this message and exit.
```

## `ilab model` Commands

```text
Usage: ilab model [OPTIONS] COMMAND [ARGS]...

  Command Group for Interacting with the Models in InstructLab.

  If this is your first time running ilab, it's best to start with `ilab init`
  to create the environment.

Options:
  --help  Show this message and exit.

Commands:
  chat      Run a chat using the modified model
  convert   Converts model to GGUF
  download  Download the model(s) to train
  serve     Start a local server
  test      Runs basic test to ensure model correctness
  train     Takes synthetic data generated locally with `ilab generate`...
```

### `ilab model chat` Command

```text
Usage: ilab model chat [OPTIONS] [QUESTION]...

  Run a chat using the modified model

Options:
  -m, --model TEXT          Model name to print in chat process  [default:
                            models/merlinite-7b-lab-Q4_K_M.gguf]
  -c, --context TEXT        Name of system context in config file.  [default:
                            default]
  -s, --session FILENAME    Filepath of a dialog session file.
  -qq, --quick-question     Exit after answering question.
  -gm, --greedy-mode        Use model greedy decoding. Useful for debugging
                            and reproducing errors.
  --max-tokens INTEGER      Set a maximum number of tokens to request from the
                            model endpoint.
  --endpoint-url TEXT       Custom URL endpoint for OpenAI-compatible API.
                            Defaults to the `ilab model serve` endpoint.
  --api-key TEXT            API key for API endpoint. [default:
                            config.DEFAULT_API_KEY]
  --tls-insecure            Disable TLS verification.
  --tls-client-cert PATH    Path to the TLS client certificate to use.
  --tls-client-key PATH     Path to the TLS client key to use.
  --tls-client-passwd TEXT  TLS client certificate password.
  --model-family TEXT       Force model family to use when picking a chat
                            template
  --help                    Show this message and exit.
```

### `ilab model convert` Command

```text
Usage: ilab model convert [OPTIONS]

  Converts model to GGUF

Options:
  --model-dir TEXT         Base directory where model is stored.  [default:
                           instructlab-merlinite-7b-lab-mlx-q]
  --adapter-file TEXT      LoRA adapter to fuse.
  -sd, --skip-de-quantize  Skip de-quantization.
  -sq, --skip-quantize     Whether to skip quantization while converting to
                           GGUF.
  --model-name TEXT        Name of the model being trained/converted. Informs
                           the naming of the final trained model file
  --help                   Show this message and exit.
```

### `ilab model download` Command

```text
Usage: ilab model download [OPTIONS]

  Download the model(s) to train

Options:
  --repository TEXT  Hugging Face repository of the model to download.
                     [default: instructlab/merlinite-7b-lab-GGUF]
  --release TEXT     The git revision of the model to download - e.g. a
                     branch, tag, or commit hash.  [default: main]
  --filename TEXT    Name of the model file to download from the Hugging Face
                     repository.  [default: merlinite-7b-lab-Q4_K_M.gguf]
  --model-dir TEXT   The local directory to download the model files into.
                     [default: models]
  --hf-token TEXT    User access token for connecting to the Hugging Face Hub.
  --help             Show this message and exit.
```

### `ilab model serve` Command

```text
Usage: ilab model serve [OPTIONS]

  Start a local server

Options:
  --model-path PATH       Path to the model used during generation.  [default:
                          models/merlinite-7b-lab-Q4_K_M.gguf]
  --gpu-layers INTEGER    The number of layers to put on the GPU. The rest
                          will be on the CPU. Defaults to -1 to move all to
                          GPU.
  --num-threads INTEGER   The number of CPU threads to use.
  --max-ctx-size INTEGER  The context size is the maximum number of tokens
                          considered by the model, for both the prompt and
                          response. Defaults to 4096.
  --model-family TEXT     Model family is used to specify which chat template
                          to serve with
  --log-file PATH         Log file path to write server logs to.
  --help                  Show this message and exit.
```

### `ilab model test` Command

```text
Usage: ilab model test [OPTIONS]

  Runs basic test to ensure model correctness

Options:
  --data-dir TEXT      Base directory where data is stored.  [default:
                       ./taxonomy_data]
  --model-dir TEXT     Base directory where model is stored.  [default:
                       instructlab-merlinite-7b-lab-mlx-q]
  --adapter-file TEXT  LoRA adapter to use for test. Set to 'None' to force
                       only testing behavior from before training.  [default:
                       auto]
  --help               Show this message and exit.
```

### `ilab model train` Command

```text
Usage: ilab model train [OPTIONS]

  Takes synthetic data generated locally with `ilab generate` and the previous
  model and learns a new model using the MLX API. On success, writes newly
  learned model to {model_dir}/mlx_model, which is where `chatmlx` will look
  for a model.

Options:
  --data-dir TEXT          Base directory where data is stored.
  --input-dir PATH         Path to generated files to use as input.
  --skip-preprocessing
  --tokenizer-dir TEXT     Base directory where tokenizer is stored.
  --gguf-model-path TEXT   Local directory where gguf model is stored.
  --model-dir TEXT         Base directory where model is stored.  [default:
                           instructlab/merlinite-7b-lab]
  --iters INTEGER          Number of iterations to train LoRA.
  --local                  Whether or not `model_dir` is remote from
                           HuggingFace.
  -sq, --skip-quantize     Whether to skip quantization while converting to
                           MLX. This parameter will be ignored if --gguf-
                           model-path and --tokenizer-dir are specified.
  --num-epochs INTEGER     The number of times the training data is passed
                           through the training algorithm. Please note that
                           this value is used on Linux platforms only.
                           [default: 1]
  --device [cpu|cuda|hpu]  PyTorch device for Linux training. Use 'cuda' for
                           NVidia CUDA / AMD ROCm GPU, to use specific GPU,
                           set visible GPU before run train command.
                           [default: cpu]
  --model-name TEXT        model name to use in training  [default:
                           instructlab/merlinite-7b-lab]
  --help                   Show this message and exit.
```

## `ilab sysinfo` Commands

```text
Usage: ilab sysinfo [OPTIONS]

  Print system information

Options:
  --help  Show this message and exit.
```

## `ilab taxonomy` Commands

```text
Usage: ilab taxonomy [OPTIONS] COMMAND [ARGS]...

  Command Group for Interacting with the Taxonomy of InstructLab.

  If this is your first time running ilab, it's best to start with `ilab init`
  to create the environment.

Options:
  --help  Show this message and exit.

Commands:
  diff  Lists taxonomy files that have changed since <taxonomy-base> and...
```

### `ilab taxonomy diff` Command

```text
Usage: ilab taxonomy diff [OPTIONS]

  Lists taxonomy files that have changed since <taxonomy-base> and checks that
  taxonomy is valid. Similar to 'git diff <ref>'.

Options:
  --taxonomy-path PATH  Path to https://github.com/instructlab/taxonomy.git
                        clone or local file path.
  --taxonomy-base TEXT  Base git-ref to use for taxonomy.
  --yaml-rules PATH     Custom rules file for YAML linting.
  --quiet               Suppress all output. Call returns 0 if check passes, 1
                        otherwise.
  --help                Show this message and exit.
```
