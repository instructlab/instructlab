{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Copy qna.yaml to the root and it will be provisioned to taxonomy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SvUfCCjw_9lX",
    "outputId": "6cd86bfd-1d1a-404b-bc36-2f8b43d5490e"
   },
   "source": [
    "# Clone and upload the instruct-lab/cli project to the workspace.  Once public access to instruct-lab/cli is opened, cloning can be done in this notebook.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once CUDA is available in instruct-lab/cli(see https://github.com/instruct-lab/cli/pull/520), uncomment to enable CUDA\n",
    "#!CMAKE_ARGS=\"-DLLAMA_CUBLAS=on\" pip3 install --force-reinstall --no-cache-dir llama-cpp-python\n",
    "!cd cli && pip3 install .\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9w_NFZ5mA1c6",
    "outputId": "0f7be4db-1962-4175-c7ab-6dae82bb00c3"
   },
   "outputs": [],
   "source": [
    "!lab init --non-interactive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rMJjjL-kDlba",
    "outputId": "0fd80f16-0ab0-45c6-ef5f-7586e6e55f10"
   },
   "outputs": [],
   "source": [
    "!lab download"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# replace localhost with 0.0.0.0\n",
    "!grep -rl 'localhost' /content/config.yaml | xargs sed -i 's/localhost/0.0.0.0/g'\n",
    "!cp /content/qna.yaml /content/taxonomy/compositional_skills/writing/grounded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rdncIqohD_Qb",
    "outputId": "2e8c11b3-7f41-42f3-ae9b-d859b72d5435"
   },
   "outputs": [],
   "source": [
    "# Start the server\n",
    "import subprocess\n",
    "\n",
    "# Define the command and arguments for the background process\n",
    "command = ['lab', 'serve']\n",
    "\n",
    "# Spawn the background process\n",
    "process = subprocess.Popen(command)\n",
    "\n",
    "# Continue with the rest of your program\n",
    "print('Background process has been started.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!lab generate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Once CUDA is available in instruct-lab/cli(see https://github.com/instruct-lab/cli/pull/520), uncomment to enable CUDA\n",
    "#!lab train --device cuda\n",
    "!lab train"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "machine_shape": "hm",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
